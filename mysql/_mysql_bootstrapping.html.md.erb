This topic describes how to bootstrap your MySQL cluster in the event of a
cluster failure.

You can bootstrap your cluster by using one of two methods:

- Run the bootstrap errand. See [Run the Bootstrap Errand](#assisted-bootstrap) below.
- Bootstrap manually. See [Bootstrap Manually](#manual-bootstrap) below.

## <a id="when-to-bootstrap"></a> When to Bootstrap

You must bootstrap a cluster that loses quorum. A cluster loses quorum when fewer than half the
 nodes can communicate with each other for longer than the configured grace period. If a cluster
 does not lose quorum, individual unhealthy nodes automatically rejoin the cluster after resolving
 the error, restarting the node, or restoring connectivity.

To check whether your cluster has lost quorum, look for the following symptoms:

- All nodes appear "Unhealthy" on the proxy dashboard. <% if vars.product_short == "Tanzu SQL for VMs" %>
The proxy dashboard is viewable at <%= vars.switchboard_url %>.
<% else %> To log in to the proxy dashboard, see
[Log In to Proxy Dashboard](#proxy-dashboard-login) below.<% end %>
![Screenshot of the Switchboard dashboard.
At the top, there is a banner with the message '3 out of 3 nodes are unhealthy'.
Below this is a table with the headings nodes, status, current sessions, and IP address.
For each node in the table, the status column is marked unhealthy.](quorum-lost.png)

- All responsive nodes report the value of `wsrep_cluster_status` as `non-Primary`:
    <pre class="terminal">
    mysql> SHOW STATUS LIKE 'wsrep_cluster_status';
    +----------------------+-------------+
    | Variable_name        | Value       |
    +----------------------+-------------+
    | wsrep_cluster_status | non-Primary |
    +----------------------+-------------+
    </pre>
<% # Is it responsive or unresponsive? %>

- All unresponsive nodes respond with `ERROR 1047` when using most statement types
in the MySQL client:

    <pre class="terminal">
    mysql> select * from mysql.user;
    ERROR 1047 (08S01) at line 1: WSREP has not yet prepared node for application use
    </pre>

For more information about checking the state of your cluster, see
[Check Cluster State](https://docs.pivotal.io/p-mysql/1-10/troubleshooting.html#check-state).

<% # The following is steps to log in to the proxy dashboard for internal MySQL %>
<% if vars.product_short != "Tanzu SQL for VMs" %>

## <a id="proxy-dashboard-login"></a> Log In to Proxy Dashboard

To log in to the proxy dashboard:

1. Get the proxy dashboard credentials by entering the following URL into your web browser
and recording the output:<pre>
    http<span>s</span>://OPS-MAN-FQDN/api/v0/deployed/products/<%= vars.app_runtime_abbr.parameterize.upcase %>-GUID/variables?name=mysql-proxy-dashboard-credentials
</pre>
    Where:
    - `OPS-MAN-FQDN` is the fully-qualified domain name (FQDN) for your <%= vars.ops_manager %>
    deployment.
    - `<%= vars.app_runtime_abbr.parameterize.upcase %>-GUID` is the GUID of your
    <%= vars.app_runtime_abbr %> tile. For more information about finding your GUID,
    see the [Ops Manager API documentation](https://docs.pivotal.io/platform/opsman-api/#tag/Products/paths/~1api~1v0~1deployed~1products/get)

1. Log in to the proxy dashboard by entering the following URL into your web browser: <pre>
http<span>s</span>://BOSH-JOB-INDEX-proxy-p-mysql-ert.YOUR-SYSTEM-DOMAIN/
</pre>
    Where:
    - `BOSH-JOB-INDEX` is `0`, `1`, or `2`, representing the three proxies deployed on each node.
    - `SYSTEM-DOMAIN` is the **System domain** you configured in the **Domains** pane of the BOSH Director tile.
<% end %>


## <a id="assisted-bootstrap"></a> Run the Bootstrap Errand

<%= vars.product_full %> includes a
[BOSH errand](http://bosh.io/docs/jobs.html#jobs-vs-errands) that automates the manual
bootstrapping procedure in the [Bootstrap Manually](#manual-bootstrap) section below.

It finds the node with the highest transaction sequence number and asks it to
start up by itself (i.e. in bootstrap mode) and then asks the remaining nodes
to join the cluster.

In most cases, running the errand recovers your cluster.
But, certain scenarios require additional steps.

### <a id="determine-failure"></a> Determine Type of Cluster Failure

To determine which set of instructions to follow:

1. List your MySQL instances by running:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT instances
    ```

    Where:
    - `YOUR-ENV` is the environment where you deployed the cluster.
    - `YOUR-DEPLOYMENT` is the deployment cluster name.

    For example:
    <pre class="terminal">
    $ bosh -e prod -d mysql instances
    </pre>

1. Find and record the `Process State` for your MySQL instances.
    <a id="vms"></a>In the following example output, the MySQL instances are in the `failing` process state.
    <pre class="terminal">
    Instance                                                             Process State  AZ             IPs
    backup-restore/c635410e-917d-46aa-b054-86d222b6d1c0                  running        us-central1-b  10.0.4.47
    bootstrap/a31af4ff-e1df-4ff1-a781-abc3c6320ed4                       -              us-central1-b  -
    broker-registrar/1a93e53d-af7c-4308-85d4-3b2b80d504e4                -              us-central1-b  10.0.4.58
    cf-mysql-broker/137d52b8-a1b0-41f3-847f-c44f51f87728                 running        us-central1-c  10.0.4.57
    cf-mysql-broker/28b463b1-cc12-42bf-b34b-82ca7c417c41                 running        us-central1-b  10.0.4.56
    deregister-and-purge-instances/4cb93432-4d90-4f1d-8152-d0c238fa5aab  -              us-central1-b  -
    monitoring/f7117dcb-1c22-495e-a99e-cf2add90dea9                      running        us-central1-b  10.0.4.48
    mysql/220fe72a-9026-4e2e-9fe3-1f5c0b6bf09b                           failing        us-central1-b  10.0.4.44
    mysql/28a210ac-cb98-4ab4-9672-9f4c661c57b8                           failing        us-central1-f  10.0.4.46
    mysql/c1639373-26a2-44ce-85db-c9fe5a42964b                           failing        us-central1-c  10.0.4.45
    proxy/87c5683d-12f5-426c-b925-62521529f64a                           running        us-central1-b  10.0.4.60
    proxy/b0115ccd-7973-42d3-b6de-edb5ae53c63e                           running        us-central1-c  10.0.4.61
    rejoin-unsafe/8ce9370a-e86b-4638-bf76-e103f858413f                   -              us-central1-b  -
    smoke-tests/e026aaef-efd9-4644-8d14-0811cb1ba733                     -              us-central1-b  10.0.4.59
    </pre>

1. Choose your scenario:
    * If your MySQL instances are in the `failing` state, continue to
    [Scenario 1](#cluster-disrupted).
    * If your MySQL instances are in the ` - ` state, continue to
    [Scenario 2](#vms-terminated).

### <a id="cluster-disrupted"></a> Scenario 1: VMs Running, Cluster Disrupted ##

In this scenario, the VMs are running, but the cluster has been disrupted.

To bootstrap in this scenario:


<% # Ask a person about this. Is this step necessary? %>


<% # 1. To select the correct deployment, run the following command: %>

<% #     ``` %>
<% #     bosh deployment PATH-TO-DEPLOYMENT-MANIFEST %>
<% #     ``` %>
<% #     Where `PATH-TO-DEPLOYMENT-MANIFEST` is the path to your deployment manifest. %>

1. Run the bootstrap errand on the VM where the bootstrap errand is co-located, by running:

<% if vars.product_short == "Tanzu SQL for VMs" %>
    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT run-errand --instance=mysql/0 bootstrap
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.
<% else %>
    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT run-errand --instance=VM bootstrap
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.
    + `VM` is `clock_global/0` if you use TAS for VMs and
      `control/0` if you use Small Footprint TAS for VMs.
<% end %>

    <p class="note"><strong>Note:</strong> The errand runs for a long time, during which no output is returned.</p>

    The command returns many lines of output, eventually followed by:
    <pre class="terminal">
    Bootstrap errand completed
    [stderr]
    + echo 'Started bootstrap errand ...'
    + JOB\_DIR=/var/vcap/jobs/bootstrap
    + CONFIG\_PATH=/var/vcap/jobs/bootstrap/config/config.yml
    + /var/vcap/packages/bootstrap/bin/cf-mysql-bootstrap -configPath=/var/vcap/jobs/bootstrap/config/config.yml
    + echo 'Bootstrap errand completed'
    + exit 0
    Errand 'bootstrap' completed successfully (exit code 0)
    </pre>

1. If the errand fails, run the bootstrap errand command again after a
few minutes. The bootstrap errand might not work the first time.

1. If the errand fails after several tries, bootstrap your cluster manually.
See [Bootstrap Manually](#manual-bootstrap) below.

### <a id="vms-terminated"></a> Scenario 2: VMs Terminated or Lost ##

In severe circumstances, such as a power failure, it is possible to lose all your VMs.
You must re-create them before you can begin recovering the cluster.

When MySQL instances are in the ` - ` state, the VMs are lost. The procedures in
this scenario bring the instances from a ` - ` state to a `failing` state.
Then you run the bootstrap errand similar to [Scenario 1](#cluster-disrupted)
above and restore configuration.

To recover terminated or lost VMs, follow the procedures in the sections below:

1. [Re-create the Missing VMs](#recreate): Bring MySQL instances from a ` - `
state to a `failing` state.

1. [Run the Bootstrap Errand](#run-the-errand): Because your instances are now
in the `failing` state, continue similarly to [Scenario 1](#cluster-disrupted) above.

1. [Restore the BOSH Configuration](#reset-deployment): Go back to unignoring all
instances and redeploy. This is a critical and mandatory step.

<p class="warning note"><strong>Warning:</strong>
  If you do not set each of your ignored instances to <code>unignore</code>,
  your instances are not updated in future deploys.
  You must follow the procedure in the final section of <em>Scenario 2</em>,
  <a href="#reset-deployment">Restore the BOSH Configuration</a>.
</p>

#### <a id="recreate"></a> Re-create the Missing VMs

The procedure in this section uses BOSH to re-create the
VMs, install software on them, and try to start the jobs.

The procedure below allows you to:

-  Redeploy your cluster while expecting the jobs to fail.

- Instruct BOSH to ignore the state of each instance in your cluster. This allows
BOSH to deploy the software to each instance even if the instance is failing.

To re-create your missing VMs:

<% # node or bosh vm %>

1. If BOSH Resurrector is enabled, disable it by running:

    ```
    bosh -e YOUR-ENV update-resurrection off
    ```

    Where `YOUR-ENV` is the name of your environment.

1. Download the current manifest by running:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT manifest > /tmp/manifest.yml
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.

1. Redeploy deployment by running:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT deploy /tmp/manifest.yml
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.

    <p class="note"><strong>Note:</strong> Expect one of the MySQL VMs to fail. Deploying causes BOSH
      to create new VMs and install the software. Forming a cluster is in a
      subsequent step.</p>

1. View the instance GUID of the VM that attempted to start by running:

      ```
      bosh -e YOUR-ENV -d YOUR-DEPLOYMENT instances
      ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.

    Record the instance GUID, which is the string after `mysql/` in your BOSH instances output.

1. Instruct BOSH to ignore each MySQL VM by running:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT ignore mysql/INSTANCE-GUID
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.
    + `INSTANCE-GUID` is the GUID of your instance you recorded in the above step.

1. Repeat steps 4 and 5 until all instances have attempted to start.

1. If you disabled the BOSH Resurrector in step 2, re-enable it by running:

    ```
    bosh -e YOUR-ENV update-resurrection on
    ```

    Where `YOUR-ENV` is the name of your environment.

1. Confirm that your MySQL instances have gone from the ` - ` state to the
`failing` state by running:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT instances
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.

#### <a id="run-the-errand"></a> Run the Bootstrap Errand

After you re-create the VMs, all instances now have a `failing` process state and have the MySQL code.
You must run the bootstrap errand to recover the cluster.

To bootstrap:

1. Run the bootstrap errand by running:

<% if vars.product_short == "Tanzu SQL for VMs" %>
    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT run-errand --instance=mysql/0 bootstrap
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.
<% else %>
    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT run-errand --instance=VM bootstrap
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.
    + `VM` is `clock_global/0` if you use TAS for VMs and
      `control/0` if you use Small Footprint TAS for VMs.
<% end %>

    <p class="note"><strong>Note:</strong> The errand runs for a long time,
      during which no output is returned.</p>

      The command returns many lines of output,
      eventually with the following successful output:

      <pre class="terminal">
      Bootstrap errand completed
      [stderr]
      echo 'Started bootstrap errand ...'
      JOB\_DIR=/var/vcap/jobs/bootstrap
      CONFIG\_PATH=/var/vcap/jobs/bootstrap/config/config.yml
      /var/vcap/packages/bootstrap/bin/cf-mysql-bootstrap -configPath=/var/vcap/jobs/bootstrap/config/config.yml
      echo 'Bootstrap errand completed'
      exit 0
      Errand 'bootstrap' completed successfully (exit code 0)
      </pre>

1. If the errand fails, run the bootstrap errand command again after a few minutes.
   The bootstrap errand might not work immediately.

1. See that the errand completes successfully in the shell output and continue to
[Restore the BOSH Configuration](#reset-deployment) below.
    <p class="note"><strong>Note:</strong> After you complete the bootstrap
      errand, you might still see instances in the <code>failing</code> state.
      Continue to the next section anyway.</p>

#### <a id="reset-deployment"></a> Restore the BOSH Configuration

<p class="note warning">
  <strong>Warning:</strong> If you do not set each of your ignored instances
  to <code>unignore</code>, your instances are never updated in future deploys.
</p>

To restore your BOSH configuration to its previous state, this procedure
unignores each instance that was previously ignored:

1. For each ignored instance, run:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT unignore mysql/INSTANCE-GUID
    ```
    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.
    + `INSTANCE-GUID` is the GUID of your instance.

1. Redeploy your deployment by running:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT deploy
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.

1. Verify that all `mysql` instances are in a `running` state by running:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT instances
    ```

    Where:
    + `YOUR-ENV` is the name of your environment.
    + `YOUR-DEPLOYMENT` is the name of your deployment.

## <a id="manual-bootstrap"></a>Bootstrap Manually

If the bootstrap errand is not able to automatically recover the cluster,
you need to do the steps manually.

Follow the procedures in the sections below to manually bootstrap your cluster.

<p class="note warning">
  <strong>Warning</strong>: The following procedures are prone to user-error
  and can result in lost data if followed incorrectly.
  Follow the procedure in <a href="#assisted-bootstrap">Bootstrap with the BOSH Errand</a>
  above first, and only resort to the manual process if the errand fails to repair the cluster.
</p>

### <a id="shut-down"></a> Shut Down MySQL

Follow these steps to stop the `galera-init` process for each node in the cluster.
For each node, record if the `monit stop` command was successful:

1. SSH into the node using the procedure in
   [BOSH SSH](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#bosh-ssh).

1. To shut down the `mysqld` process on the node, run:

    ```
    monit stop galera-init
    ```

1. Record if the monit command succeeds or exits with an error:
    + **If monit succeeds in stopping `galera-init`,** then you can use monit to restart this node.
     Follow all the steps below including the steps marked **Monit Restart**
     but omitting the steps marked **Manual Redeploy**.<br><br>
    + **If monit exits with the following error,** then you must manually deploy this node:

        <pre class="terminal">
        Warning: include files not found '/var/vcap/monit/job/*.monitrc'
        monit: action failed -- There is no service by that name
        </pre>
        Follow all the steps below including the steps marked **Manual Redeploy**
        but omitting the steps marked **Monit Restart**.

3. Repeat the steps above for each node in the cluster.

    You cannot bootstrap the cluster unless you have shut down the `mysqld` process
    on all nodes in the cluster.

### <a id="choose-node"></a> Determine which Node to Bootstrap

<% if current_page.data.title == "Recovering From MySQL Cluster Downtime" %>

To avoid losing data, you must bootstrap from a node in the cluster that has
the highest transaction sequence number (`seqno`).

For each node in the cluster, to find its `seqno`:

1. SSH into the node using the procedure in
[BOSH SSH](https://docs.pivotal.io/pivotalcf/2-3/customizing/trouble-advanced.html#bosh-ssh).

1. Find `seqno` values in the node's Galera state file, `grastate.dat` by running:

    ```
    cat /var/vcap/store/pxc-mysql/grastate.dat | grep 'seqno:'
    ```

1. Do one of the following, based on the last and highest `seqno` value in the `grep` output above:
  - **If `seqno` is a positive integer**, then the node shut down gracefully.
    Record this number for comparison with the latest `seqno` of other nodes in the cluster.
  - **If `seqno` is `-1`**, then the node crashed or was stopped.
    Proceed as follows to attempt to recover the `seqno` from the database:
      1. Temporarily start the database and append the last sequence number to its error log by running:

            ```
            /var/vcap/packages/pxc/bin/mysqld --defaults-file=/var/vcap/jobs/pxc-mysql/config/my.cnf --wsrep-recover
            ```
       1. Scan the end of the error log `mysql.err.log` for the recovered `seqno`.
       It appears after the group ID (a UUID) and a colon.
       For example, in the following output the recovered `seqno` is `15026`:
        <pre class="terminal">
        $ grep "Recovered position" /var/vcap/sys/log/pxc-mysql/mysql.err.log | tail -1
        150225 18:09:42 mysqld_safe WSREP: Recovered position e93955c7-b797-11e4-9faa-9a6f0b73eb46:15026
        </pre>
        1. If the node never connected to the cluster before crashing, it might not have been
        assigned a group ID. In this case, there is nothing to recover.
        Do not choose this node for bootstrapping unless all the other nodes also crashed.

4. After you retrieve the `seqno` for all nodes in your cluster, identify the one with the highest `seqno`.
If multiple nodes share the same highest `seqno`, and it is not `-1`, you can bootstrap from any of them.

<% else %>

To identify which node to bootstrap, you must find the node with the highest
transaction `sequence_number`.
The node with the highest sequence number is the one most recently updated.

To identify the node to bootstrap:

1. SSH into the node using the procedure in
   [BOSH SSH](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#bosh-ssh).

1. View the sequence number for a node by running:

    ```
    /var/vcap/jobs/pxc-mysql/bin/get-sequence-number
    ```

    When prompted confirm that you want to stop MySQL.

    For example:

    <pre class="terminal">
      $ /var/vcap/jobs/mysql/bin/get-sequence-number
      This script stops mysql. Are you sure? (y/n): y

      {"sequence_number":421,"instance_id":"012abcde-f34g-567h-ijk8-9123l4567891"}
    </pre>

1. Record the value of `sequence_number`.

1. Repeat the steps above for each node in the cluster.

1. After determining the `sequence_number` for all nodes in your cluster,
identify the node with the highest `sequence_number`.
If all nodes have the same `sequence_number`, you can choose any node as the
new bootstrap node.

<% end %>

### <a id="set-bootstrap-node"></a>Bootstrap the First Node ###

<% if current_page.data.title == "Recovering From MySQL Cluster Downtime" %>

After determining the node with the highest `seqno`, do the following
to bootstrap the node:

<p class="note"><strong>Note:</strong> Only run these bootstrap commands on the
  node with the highest <code>seqno</code>.
   Otherwise the node with the highest <code>seqno</code> is unable
   to join the new cluster unless its data is abandoned.
   Its <code>mysqld</code> process exits with an error.
   For more information about intentionally abandoning data,
   see <a href="https://docs.pivotal.io/p-mysql/1-10/architecture.html">Architecture</a>.
</p>

<% else %>

After determining the node with the highest `sequence_number`, do the following
to bootstrap the node:

<p class="note"><strong>Note:</strong> Only run these bootstrap commands on the
  node that you identified in <a href="#choose-node">Determine which Node to Bootstrap</a> above.
  Non-bootstrapped nodes abandon their data during the bootstrapping process.
  Therefore, bootstrapping off the wrong node causes data loss.
  For information about intentionally abandoning data,
   see <a href="https://docs.pivotal.io/p-mysql/1-10/architecture.html">Architecture</a>.
</p>

<% end %>

1. SSH into the node using the procedure in
   [BOSH SSH](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#bosh-ssh).

1. Update the node state to trigger its initialization of the cluster by running:

    <pre><code>echo -n "NEEDS_BOOTSTRAP" > /var/vcap/store/pxc-mysql/state.txt</code></pre>

1. **Monit Restart:** If in [Shut Down MySQL](#shut-down) above you successfully used `monit` to shut down your
`galera-init` process, then re-launch the <code>mysqld</code> process on the new bootstrap node.

  1. Start the <code>mysqld</code> process by running:

        <pre><code>monit start galera-init</code></pre>

  1. It can take up to ten minutes for <code>monit</code> to start the
    <code>mysqld </code> process.
    To confirm if the <code>mysqld</code> process has started successfully,
    run:

        <pre><code>watch monit summary</code></pre>

        If monit succeeds in starting the galera-init process,
    then the output includes the line `Process 'galera-init' running`.

1. **Manual Redeploy:** If in [Shut Down MySQL](#shut-down) above you encountered `monit` errors,
then redeploy the <code>mysqld</code> software to your bootstrap node as follows:

  1. Leave the MySQL SSH login shell and return to your local environment.

  1. Target BOSH on your bootstrap node by instructing it to ignore the other nodes in your cluster.
  For nodes all nodes except the bootstrap node you identified above, run:

        <pre><code>bosh -e YOUR-ENV -d YOUR-DEPLOYMENT ignore mysql/M
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT ignore mysql/N</code></pre>

        Where `N` and `M` are the numbers of the non-bootstrapped nodes.
        For example, if you bootstrap node 0, then `M`=1 and `N`=2.

  1. Turn off the BOSH Resurrector by running:

        <pre><code>bosh update-resurrection off</code></pre>

  1. Use the BOSH manifest to bootstrap your bootstrap machine by running:
    <pre><code>bosh -e YOUR-ENV -d YOUR-DEPLOYMENT manifest > /tmp/manifest.yml
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT deploy /tmp/manifest.yml</code></pre>

### <a id="restart-nodes"></a>Restart Remaining Nodes ###

After the bootstrapped node is running, restart the remaining nodes.

The procedure that you follow for restarting a node, depends on the output you got
for that node during [Shut Down MySQL](#shut-down) above.
Do one of the following procedures:

#### <a id="monit-restart"></a> Monit Restart

If in [Shut Down MySQL](#shut-down) above you successfully used `monit` to shut down your
`galera-init` process, then restart the nodes as follows:

1. SSH into the node using the procedure in
   [BOSH SSH](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#bosh-ssh).

1. Start the <code>mysqld</code> process with <code>monit</code> by running:

    <pre><code>monit start galera-init</code></pre>

    If the [Interruptor](https://docs.pivotal.io/p-mysql/1-10/interruptor.html)
    prevents the node from starting,
    follow the manual procedure to force the node to rejoin the cluster.
    See [How to manually force a MySQL node to rejoin if a node cannot rejoin the HA (Galera) cluster](https://community.pivotal.io/s/article/How-to-Manually-Force-a-MySQL-Node-to-Rejoin-if-a-Node-Cannot-Rejoin-the-HA-Galera-Cluster)
    in the Support knowledge base.

    <p class="note warning">
      <strong>Warning:</strong> Forcing a node to rejoin the cluster is a destructive procedure.
       Only follow the procedure with the assistance of
       <a href="https://support.pivotal.io">Support</a>.</p>

<% if current_page.data.title == "Recovering From MySQL Cluster Downtime" %>

1. If the `monit start` command fails, it might be because the node with
the highest `seqno` is `mysql/0`. <br><br>

<% else %>

1. If the `monit start` command fails, it might be because the node with
the highest `sequence_number` is `mysql/0`. <br><br>

<% end %>

    In this case:

    1. Ensure BOSH ignores updating `mysql/0` by running:

        ```
        bosh -e YOUR-ENV -d YOUR-DEPLOYMENT ignore mysql/0
        ```

        Where:
        + `YOUR-ENV` is the name of your environment.
        + `YOUR-DEPLOYMENT` is the name of your deployment.


    1. Navigate to <%= vars.ops_manager %> in a browser, log in, and click **Apply Changes**.

    1. When the deploy finishes, run the following command from the <%= vars.ops_manager %> VM:

        ```
        bosh -e YOUR-ENV -d YOUR-DEPLOYMENT unignore mysql/0
        ```

        Where:
        + `YOUR-ENV` is the name of your environment.
        + `YOUR-DEPLOYMENT` is the name of your deployment.


#### <a id="manual-redeploy"></a> Manual Redeploy

If in [Shut Down MySQL](#shut-down) above you encountered `monit` errors,
then restart the nodes as follows:

1. Instruct BOSH to no longer ignore the non-bootstrap nodes in your cluster by running:

    <pre><code>bosh -e YOUR-ENV -d YOUR-DEPLOYMENT unignore mysql/M
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT unignore mysql/N</code></pre>

    Where `N` and `M` are the numbers of the non-bootstrapped nodes.
    For example, if you bootstrap node 0, then `M`=1 and `N`=2.

1. Redeploy software to the other two nodes and have them rejoin the cluster,
   bootstrapped from the node above by running:

    ```
    bosh -e YOUR-ENV -d YOUR-DEPLOYMENT deploy /tmp/manifest.yml
    ```
    You only need to run this command once to deploy both the nodes that you unignored in the step above.

1. With your redeploys completed, turn the BOSH Resurrector back on by running:

    <pre>bosh -e YOUR-ENV update-resurrection on</pre>


### <a id="verify-nodes"></a>  Verify that the Nodes Have Joined the Cluster

The final task is to verify that all the nodes have joined the cluster.

1. SSH into the bootstrap node then run the following command to output the
total number of nodes in the cluster:

    <pre><code>mysql> SHOW STATUS LIKE 'wsrep_cluster_size';</code></pre>
